spring.application.name=multi-model-ai-project
server.port=8081

spring.ai.chat.client.enabled=false

spring.ai.ollama.base_url=http://localhost:11434
spring.ai.ollama.chat.options.model=codellama:latest
spring.ai.ollama.chat.options.temperature=0.2

#open ai

spring.ai.openai.api-key=${OPEN_API_KEY}
spring.ai.openai.chat.options.model=gpt-4.1
spring.ai.openai.chat.options.temperature=0.2
